{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "042673c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cat\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV       # hyperparam selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import matthews_corrcoef  # matric for performance evaluation in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "daa01c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../data_process/\")\n",
    "from importlib import reload\n",
    "reload(ml)\n",
    "import ML_func as ml\n",
    "import data_cleaner as dc\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b0322ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = dc.load_py(\"catboost_grid_result.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "588fbb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_depth</th>\n",
       "      <th>param_iterations</th>\n",
       "      <th>param_l2_leaf_reg</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.210669</td>\n",
       "      <td>0.120630</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 3, 'iterations': 100, 'l2_leaf_reg': 0.0, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>0.991199</td>\n",
       "      <td>0.076872</td>\n",
       "      <td>0.003799</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>0.982025</td>\n",
       "      <td>0.056673</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>0.914569</td>\n",
       "      <td>0.045270</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>0.967775</td>\n",
       "      <td>0.106905</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>0.932376</td>\n",
       "      <td>0.055728</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>0.934850</td>\n",
       "      <td>0.063939</td>\n",
       "      <td>0.003948</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>0.937332</td>\n",
       "      <td>0.026476</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>1.012809</td>\n",
       "      <td>0.110456</td>\n",
       "      <td>0.004120</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>0.968633</td>\n",
       "      <td>0.021768</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>1.369858</td>\n",
       "      <td>0.063543</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>1.334546</td>\n",
       "      <td>0.059072</td>\n",
       "      <td>0.003945</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>1.379283</td>\n",
       "      <td>0.143288</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>1.348538</td>\n",
       "      <td>0.087960</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>1.367381</td>\n",
       "      <td>0.124141</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>0.975070</td>\n",
       "      <td>0.064110</td>\n",
       "      <td>0.003730</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>1.306260</td>\n",
       "      <td>0.037060</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>1.440575</td>\n",
       "      <td>0.080489</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2920</th>\n",
       "      <td>1.430656</td>\n",
       "      <td>0.070138</td>\n",
       "      <td>0.016738</td>\n",
       "      <td>0.025857</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>1.510928</td>\n",
       "      <td>0.116620</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>1.490077</td>\n",
       "      <td>0.064779</td>\n",
       "      <td>0.004320</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2923</th>\n",
       "      <td>1.431999</td>\n",
       "      <td>0.063385</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>1.434374</td>\n",
       "      <td>0.133601</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2925</th>\n",
       "      <td>1.295648</td>\n",
       "      <td>0.018978</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2926</th>\n",
       "      <td>1.394242</td>\n",
       "      <td>0.075713</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2927</th>\n",
       "      <td>1.390262</td>\n",
       "      <td>0.055566</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2928</th>\n",
       "      <td>1.455850</td>\n",
       "      <td>0.127477</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2929</th>\n",
       "      <td>1.519854</td>\n",
       "      <td>0.107003</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>1.481931</td>\n",
       "      <td>0.152938</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2931</th>\n",
       "      <td>1.427842</td>\n",
       "      <td>0.054346</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>1.377788</td>\n",
       "      <td>0.088636</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>1.303176</td>\n",
       "      <td>0.084460</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2933</th>\n",
       "      <td>1.430218</td>\n",
       "      <td>0.134665</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.5, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>0.899838</td>\n",
       "      <td>0.013632</td>\n",
       "      <td>0.003914</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>0.936950</td>\n",
       "      <td>0.106756</td>\n",
       "      <td>0.003754</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2869</th>\n",
       "      <td>0.926557</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.0, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>0.941604</td>\n",
       "      <td>0.079001</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2871</th>\n",
       "      <td>0.887193</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2872</th>\n",
       "      <td>0.923057</td>\n",
       "      <td>0.063944</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>0.976470</td>\n",
       "      <td>0.082972</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>1.013653</td>\n",
       "      <td>0.101067</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>0.992611</td>\n",
       "      <td>0.061814</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>1.010733</td>\n",
       "      <td>0.150857</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>0.897782</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>0.898727</td>\n",
       "      <td>0.013369</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>0.933574</td>\n",
       "      <td>0.075848</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2880</th>\n",
       "      <td>0.974380</td>\n",
       "      <td>0.071278</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>0.953109</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>0.003932</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>0.995164</td>\n",
       "      <td>0.037199</td>\n",
       "      <td>0.003864</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>0.896042</td>\n",
       "      <td>0.021279</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>0.961952</td>\n",
       "      <td>0.038319</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>0.928097</td>\n",
       "      <td>0.071475</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>0.923174</td>\n",
       "      <td>0.035896</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>0.981920</td>\n",
       "      <td>0.083529</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2888</th>\n",
       "      <td>1.003627</td>\n",
       "      <td>0.089498</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2889</th>\n",
       "      <td>1.021660</td>\n",
       "      <td>0.078750</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2890</th>\n",
       "      <td>0.985174</td>\n",
       "      <td>0.073750</td>\n",
       "      <td>0.003719</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>0.931533</td>\n",
       "      <td>0.064905</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2892</th>\n",
       "      <td>0.902028</td>\n",
       "      <td>0.025837</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>0.945893</td>\n",
       "      <td>0.080782</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2894</th>\n",
       "      <td>0.944915</td>\n",
       "      <td>0.040558</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2895</th>\n",
       "      <td>0.987769</td>\n",
       "      <td>0.086189</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2896</th>\n",
       "      <td>0.949845</td>\n",
       "      <td>0.011831</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2897</th>\n",
       "      <td>0.958784</td>\n",
       "      <td>0.034641</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2898</th>\n",
       "      <td>0.989659</td>\n",
       "      <td>0.214554</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>0.929395</td>\n",
       "      <td>0.079536</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>0.981628</td>\n",
       "      <td>0.023372</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.0, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>1.418441</td>\n",
       "      <td>0.125936</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.5, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>1.445738</td>\n",
       "      <td>0.032634</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.5, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>1.429442</td>\n",
       "      <td>0.047588</td>\n",
       "      <td>0.004071</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2972</th>\n",
       "      <td>1.470080</td>\n",
       "      <td>0.075685</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2973</th>\n",
       "      <td>1.511841</td>\n",
       "      <td>0.077662</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2974</th>\n",
       "      <td>1.379992</td>\n",
       "      <td>0.037058</td>\n",
       "      <td>0.004041</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2975</th>\n",
       "      <td>1.369679</td>\n",
       "      <td>0.102916</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2976</th>\n",
       "      <td>1.350065</td>\n",
       "      <td>0.057473</td>\n",
       "      <td>0.004060</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2977</th>\n",
       "      <td>1.354318</td>\n",
       "      <td>0.087807</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>1.450497</td>\n",
       "      <td>0.088001</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>1.460705</td>\n",
       "      <td>0.089721</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2980</th>\n",
       "      <td>1.531561</td>\n",
       "      <td>0.107331</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2981</th>\n",
       "      <td>1.417848</td>\n",
       "      <td>0.103394</td>\n",
       "      <td>0.004020</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2982</th>\n",
       "      <td>1.379561</td>\n",
       "      <td>0.132730</td>\n",
       "      <td>0.003996</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2983</th>\n",
       "      <td>1.374886</td>\n",
       "      <td>0.047190</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>1.381497</td>\n",
       "      <td>0.099914</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2970</th>\n",
       "      <td>1.334618</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>1.480066</td>\n",
       "      <td>0.160752</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>1.526596</td>\n",
       "      <td>0.141892</td>\n",
       "      <td>0.004038</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>1.395288</td>\n",
       "      <td>0.042566</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2989</th>\n",
       "      <td>1.355307</td>\n",
       "      <td>0.104424</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>1.384449</td>\n",
       "      <td>0.103216</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>1.370190</td>\n",
       "      <td>0.143214</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>1.348659</td>\n",
       "      <td>0.046686</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>1.430555</td>\n",
       "      <td>0.059923</td>\n",
       "      <td>0.003813</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>1.436192</td>\n",
       "      <td>0.015754</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.09</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.09}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>1.446821</td>\n",
       "      <td>0.066231</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.3}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>1.346040</td>\n",
       "      <td>0.066778</td>\n",
       "      <td>0.004008</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.003}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>1.406244</td>\n",
       "      <td>0.110281</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.006</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.006}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>1.353413</td>\n",
       "      <td>0.102829</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.009}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>1.342222</td>\n",
       "      <td>0.037466</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.03}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>1.487713</td>\n",
       "      <td>0.078551</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>1.494836</td>\n",
       "      <td>0.087569</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>8</td>\n",
       "      <td>300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>{'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.06}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.210669      0.120630         0.003697        0.000403   \n",
       "2903       0.991199      0.076872         0.003799        0.000121   \n",
       "2904       0.982025      0.056673         0.003915        0.000432   \n",
       "2905       0.914569      0.045270         0.003879        0.000132   \n",
       "2906       0.967775      0.106905         0.003945        0.000432   \n",
       "2907       0.932376      0.055728         0.003794        0.000131   \n",
       "2908       0.934850      0.063939         0.003948        0.000348   \n",
       "2909       0.937332      0.026476         0.003824        0.000103   \n",
       "2910       1.012809      0.110456         0.004120        0.000540   \n",
       "2911       0.968633      0.021768         0.003902        0.000359   \n",
       "2912       1.369858      0.063543         0.003810        0.000113   \n",
       "2913       1.334546      0.059072         0.003945        0.000409   \n",
       "2914       1.379283      0.143288         0.004058        0.000408   \n",
       "2915       1.348538      0.087960         0.003827        0.000107   \n",
       "2916       1.367381      0.124141         0.003974        0.000397   \n",
       "2902       0.975070      0.064110         0.003730        0.000020   \n",
       "2917       1.306260      0.037060         0.004051        0.000457   \n",
       "2919       1.440575      0.080489         0.004017        0.000357   \n",
       "2920       1.430656      0.070138         0.016738        0.025857   \n",
       "2921       1.510928      0.116620         0.004148        0.000369   \n",
       "2922       1.490077      0.064779         0.004320        0.000500   \n",
       "2923       1.431999      0.063385         0.004141        0.000360   \n",
       "2924       1.434374      0.133601         0.004111        0.000421   \n",
       "2925       1.295648      0.018978         0.004188        0.000403   \n",
       "2926       1.394242      0.075713         0.004057        0.000328   \n",
       "2927       1.390262      0.055566         0.004185        0.000449   \n",
       "2928       1.455850      0.127477         0.004069        0.000393   \n",
       "2929       1.519854      0.107003         0.003926        0.000155   \n",
       "2930       1.481931      0.152938         0.004116        0.000405   \n",
       "2931       1.427842      0.054346         0.004003        0.000458   \n",
       "2932       1.377788      0.088636         0.004056        0.000358   \n",
       "2918       1.303176      0.084460         0.003738        0.000015   \n",
       "2933       1.430218      0.134665         0.004102        0.000453   \n",
       "2901       0.899838      0.013632         0.003914        0.000387   \n",
       "2899       0.936950      0.106756         0.003754        0.000080   \n",
       "2869       0.926557      0.015511         0.003891        0.000375   \n",
       "2870       0.941604      0.079001         0.003728        0.000023   \n",
       "2871       0.887193      0.016639         0.003726        0.000022   \n",
       "2872       0.923057      0.063944         0.003771        0.000073   \n",
       "2873       0.976470      0.082972         0.003789        0.000139   \n",
       "2874       1.013653      0.101067         0.003970        0.000431   \n",
       "2875       0.992611      0.061814         0.003832        0.000132   \n",
       "2876       1.010733      0.150857         0.003887        0.000386   \n",
       "2877       0.897782      0.014992         0.003885        0.000187   \n",
       "2878       0.898727      0.013369         0.003982        0.000438   \n",
       "2879       0.933574      0.075848         0.003806        0.000079   \n",
       "2880       0.974380      0.071278         0.003853        0.000159   \n",
       "2881       0.953109      0.015334         0.003932        0.000415   \n",
       "2882       0.995164      0.037199         0.003864        0.000178   \n",
       "2900       0.896042      0.021279         0.003797        0.000127   \n",
       "2883       0.961952      0.038319         0.003944        0.000347   \n",
       "2885       0.928097      0.071475         0.003987        0.000337   \n",
       "2886       0.923174      0.035896         0.003808        0.000113   \n",
       "2887       0.981920      0.083529         0.003958        0.000259   \n",
       "2888       1.003627      0.089498         0.003806        0.000108   \n",
       "2889       1.021660      0.078750         0.003987        0.000436   \n",
       "2890       0.985174      0.073750         0.003719        0.000020   \n",
       "2891       0.931533      0.064905         0.003779        0.000105   \n",
       "2892       0.902028      0.025837         0.004031        0.000377   \n",
       "2893       0.945893      0.080782         0.003873        0.000064   \n",
       "2894       0.944915      0.040558         0.004156        0.000402   \n",
       "2895       0.987769      0.086189         0.003921        0.000355   \n",
       "2896       0.949845      0.011831         0.003736        0.000013   \n",
       "2897       0.958784      0.034641         0.003771        0.000095   \n",
       "2898       0.989659      0.214554         0.003958        0.000361   \n",
       "2884       0.929395      0.079536         0.003787        0.000098   \n",
       "2868       0.981628      0.023372         0.003836        0.000106   \n",
       "2934       1.418441      0.125936         0.004129        0.000284   \n",
       "2936       1.445738      0.032634         0.003988        0.000394   \n",
       "2971       1.429442      0.047588         0.004071        0.000410   \n",
       "2972       1.470080      0.075685         0.004063        0.000406   \n",
       "2973       1.511841      0.077662         0.003884        0.000122   \n",
       "2974       1.379992      0.037058         0.004041        0.000292   \n",
       "2975       1.369679      0.102916         0.004106        0.000341   \n",
       "2976       1.350065      0.057473         0.004060        0.000403   \n",
       "2977       1.354318      0.087807         0.004015        0.000422   \n",
       "2978       1.450497      0.088001         0.004069        0.000396   \n",
       "2979       1.460705      0.089721         0.003881        0.000115   \n",
       "2980       1.531561      0.107331         0.004056        0.000377   \n",
       "2981       1.417848      0.103394         0.004020        0.000348   \n",
       "2982       1.379561      0.132730         0.003996        0.000328   \n",
       "2983       1.374886      0.047190         0.003818        0.000103   \n",
       "2984       1.381497      0.099914         0.004062        0.000463   \n",
       "2970       1.334618      0.015517         0.004079        0.000429   \n",
       "2985       1.480066      0.160752         0.004088        0.000337   \n",
       "2987       1.526596      0.141892         0.004038        0.000395   \n",
       "2988       1.395288      0.042566         0.004119        0.000275   \n",
       "2989       1.355307      0.104424         0.004074        0.000394   \n",
       "2990       1.384449      0.103216         0.004019        0.000180   \n",
       "2991       1.370190      0.143214         0.004052        0.000385   \n",
       "2992       1.348659      0.046686         0.003995        0.000391   \n",
       "2993       1.430555      0.059923         0.003813        0.000097   \n",
       "2994       1.436192      0.015754         0.004085        0.000366   \n",
       "2995       1.446821      0.066231         0.004033        0.000451   \n",
       "2996       1.346040      0.066778         0.004008        0.000461   \n",
       "2997       1.406244      0.110281         0.004069        0.000324   \n",
       "2998       1.353413      0.102829         0.003908        0.000128   \n",
       "2999       1.342222      0.037466         0.003974        0.000368   \n",
       "3000       1.487713      0.078551         0.004016        0.000378   \n",
       "2986       1.494836      0.087569         0.004691        0.000443   \n",
       "\n",
       "     param_depth param_iterations param_l2_leaf_reg param_learning_rate  \\\n",
       "0              3              100               0.0               0.003   \n",
       "2903           8              200               5.5                0.09   \n",
       "2904           8              200               5.5                 0.3   \n",
       "2905           8              200               6.0               0.003   \n",
       "2906           8              200               6.0               0.006   \n",
       "2907           8              200               6.0               0.009   \n",
       "2908           8              200               6.0                0.03   \n",
       "2909           8              200               6.0                0.06   \n",
       "2910           8              200               6.0                0.09   \n",
       "2911           8              200               6.0                 0.3   \n",
       "2912           8              300               0.0               0.003   \n",
       "2913           8              300               0.0               0.006   \n",
       "2914           8              300               0.0               0.009   \n",
       "2915           8              300               0.0                0.03   \n",
       "2916           8              300               0.0                0.06   \n",
       "2902           8              200               5.5                0.06   \n",
       "2917           8              300               0.0                0.09   \n",
       "2919           8              300               0.5               0.003   \n",
       "2920           8              300               0.5               0.006   \n",
       "2921           8              300               0.5               0.009   \n",
       "2922           8              300               0.5                0.03   \n",
       "2923           8              300               0.5                0.06   \n",
       "2924           8              300               0.5                0.09   \n",
       "2925           8              300               0.5                 0.3   \n",
       "2926           8              300               1.0               0.003   \n",
       "2927           8              300               1.0               0.006   \n",
       "2928           8              300               1.0               0.009   \n",
       "2929           8              300               1.0                0.03   \n",
       "2930           8              300               1.0                0.06   \n",
       "2931           8              300               1.0                0.09   \n",
       "2932           8              300               1.0                 0.3   \n",
       "2918           8              300               0.0                 0.3   \n",
       "2933           8              300               1.5               0.003   \n",
       "2901           8              200               5.5                0.03   \n",
       "2899           8              200               5.5               0.006   \n",
       "2869           8              200               3.0                 0.3   \n",
       "2870           8              200               3.5               0.003   \n",
       "2871           8              200               3.5               0.006   \n",
       "2872           8              200               3.5               0.009   \n",
       "2873           8              200               3.5                0.03   \n",
       "2874           8              200               3.5                0.06   \n",
       "2875           8              200               3.5                0.09   \n",
       "2876           8              200               3.5                 0.3   \n",
       "2877           8              200               4.0               0.003   \n",
       "2878           8              200               4.0               0.006   \n",
       "2879           8              200               4.0               0.009   \n",
       "2880           8              200               4.0                0.03   \n",
       "2881           8              200               4.0                0.06   \n",
       "2882           8              200               4.0                0.09   \n",
       "2900           8              200               5.5               0.009   \n",
       "2883           8              200               4.0                 0.3   \n",
       "2885           8              200               4.5               0.006   \n",
       "2886           8              200               4.5               0.009   \n",
       "2887           8              200               4.5                0.03   \n",
       "2888           8              200               4.5                0.06   \n",
       "2889           8              200               4.5                0.09   \n",
       "2890           8              200               4.5                 0.3   \n",
       "2891           8              200               5.0               0.003   \n",
       "2892           8              200               5.0               0.006   \n",
       "2893           8              200               5.0               0.009   \n",
       "2894           8              200               5.0                0.03   \n",
       "2895           8              200               5.0                0.06   \n",
       "2896           8              200               5.0                0.09   \n",
       "2897           8              200               5.0                 0.3   \n",
       "2898           8              200               5.5               0.003   \n",
       "2884           8              200               4.5               0.003   \n",
       "2868           8              200               3.0                0.09   \n",
       "2934           8              300               1.5               0.006   \n",
       "2936           8              300               1.5                0.03   \n",
       "2971           8              300               4.0                0.03   \n",
       "2972           8              300               4.0                0.06   \n",
       "2973           8              300               4.0                0.09   \n",
       "2974           8              300               4.0                 0.3   \n",
       "2975           8              300               4.5               0.003   \n",
       "2976           8              300               4.5               0.006   \n",
       "2977           8              300               4.5               0.009   \n",
       "2978           8              300               4.5                0.03   \n",
       "2979           8              300               4.5                0.06   \n",
       "2980           8              300               4.5                0.09   \n",
       "2981           8              300               4.5                 0.3   \n",
       "2982           8              300               5.0               0.003   \n",
       "2983           8              300               5.0               0.006   \n",
       "2984           8              300               5.0               0.009   \n",
       "2970           8              300               4.0               0.009   \n",
       "2985           8              300               5.0                0.03   \n",
       "2987           8              300               5.0                0.09   \n",
       "2988           8              300               5.0                 0.3   \n",
       "2989           8              300               5.5               0.003   \n",
       "2990           8              300               5.5               0.006   \n",
       "2991           8              300               5.5               0.009   \n",
       "2992           8              300               5.5                0.03   \n",
       "2993           8              300               5.5                0.06   \n",
       "2994           8              300               5.5                0.09   \n",
       "2995           8              300               5.5                 0.3   \n",
       "2996           8              300               6.0               0.003   \n",
       "2997           8              300               6.0               0.006   \n",
       "2998           8              300               6.0               0.009   \n",
       "2999           8              300               6.0                0.03   \n",
       "3000           8              300               6.0                0.06   \n",
       "2986           8              300               5.0                0.06   \n",
       "\n",
       "                                                                           params  \\\n",
       "0     {'depth': 3, 'iterations': 100, 'l2_leaf_reg': 0.0, 'learning_rate': 0.003}   \n",
       "2903   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.09}   \n",
       "2904    {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.3}   \n",
       "2905  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.003}   \n",
       "2906  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.006}   \n",
       "2907  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.009}   \n",
       "2908   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.03}   \n",
       "2909   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.06}   \n",
       "2910   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.09}   \n",
       "2911    {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 6.0, 'learning_rate': 0.3}   \n",
       "2912  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.003}   \n",
       "2913  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.006}   \n",
       "2914  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.009}   \n",
       "2915   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.03}   \n",
       "2916   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.06}   \n",
       "2902   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.06}   \n",
       "2917   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.09}   \n",
       "2919  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.003}   \n",
       "2920  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.006}   \n",
       "2921  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.009}   \n",
       "2922   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.03}   \n",
       "2923   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.06}   \n",
       "2924   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.09}   \n",
       "2925    {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.5, 'learning_rate': 0.3}   \n",
       "2926  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.003}   \n",
       "2927  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.006}   \n",
       "2928  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.009}   \n",
       "2929   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.03}   \n",
       "2930   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.06}   \n",
       "2931   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.09}   \n",
       "2932    {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.0, 'learning_rate': 0.3}   \n",
       "2918    {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 0.0, 'learning_rate': 0.3}   \n",
       "2933  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.5, 'learning_rate': 0.003}   \n",
       "2901   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.03}   \n",
       "2899  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.006}   \n",
       "2869    {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.0, 'learning_rate': 0.3}   \n",
       "2870  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.003}   \n",
       "2871  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.006}   \n",
       "2872  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.009}   \n",
       "2873   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.03}   \n",
       "2874   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.06}   \n",
       "2875   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.09}   \n",
       "2876    {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.5, 'learning_rate': 0.3}   \n",
       "2877  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.003}   \n",
       "2878  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.006}   \n",
       "2879  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.009}   \n",
       "2880   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.03}   \n",
       "2881   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.06}   \n",
       "2882   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.09}   \n",
       "2900  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.009}   \n",
       "2883    {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.0, 'learning_rate': 0.3}   \n",
       "2885  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.006}   \n",
       "2886  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.009}   \n",
       "2887   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.03}   \n",
       "2888   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.06}   \n",
       "2889   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.09}   \n",
       "2890    {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.3}   \n",
       "2891  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.003}   \n",
       "2892  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.006}   \n",
       "2893  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.009}   \n",
       "2894   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.03}   \n",
       "2895   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.06}   \n",
       "2896   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.09}   \n",
       "2897    {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.0, 'learning_rate': 0.3}   \n",
       "2898  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 5.5, 'learning_rate': 0.003}   \n",
       "2884  {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 4.5, 'learning_rate': 0.003}   \n",
       "2868   {'depth': 8, 'iterations': 200, 'l2_leaf_reg': 3.0, 'learning_rate': 0.09}   \n",
       "2934  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.5, 'learning_rate': 0.006}   \n",
       "2936   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 1.5, 'learning_rate': 0.03}   \n",
       "2971   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.03}   \n",
       "2972   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.06}   \n",
       "2973   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.09}   \n",
       "2974    {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.3}   \n",
       "2975  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.003}   \n",
       "2976  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.006}   \n",
       "2977  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.009}   \n",
       "2978   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.03}   \n",
       "2979   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.06}   \n",
       "2980   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.09}   \n",
       "2981    {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.5, 'learning_rate': 0.3}   \n",
       "2982  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.003}   \n",
       "2983  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.006}   \n",
       "2984  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.009}   \n",
       "2970  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 4.0, 'learning_rate': 0.009}   \n",
       "2985   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.03}   \n",
       "2987   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.09}   \n",
       "2988    {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.3}   \n",
       "2989  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.003}   \n",
       "2990  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.006}   \n",
       "2991  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.009}   \n",
       "2992   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.03}   \n",
       "2993   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.06}   \n",
       "2994   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.09}   \n",
       "2995    {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.5, 'learning_rate': 0.3}   \n",
       "2996  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.003}   \n",
       "2997  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.006}   \n",
       "2998  {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.009}   \n",
       "2999   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.03}   \n",
       "3000   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 6.0, 'learning_rate': 0.06}   \n",
       "2986   {'depth': 8, 'iterations': 300, 'l2_leaf_reg': 5.0, 'learning_rate': 0.06}   \n",
       "\n",
       "      split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0                   1.0                1.0                1.0   \n",
       "2903                1.0                1.0                1.0   \n",
       "2904                1.0                1.0                1.0   \n",
       "2905                1.0                1.0                1.0   \n",
       "2906                1.0                1.0                1.0   \n",
       "2907                1.0                1.0                1.0   \n",
       "2908                1.0                1.0                1.0   \n",
       "2909                1.0                1.0                1.0   \n",
       "2910                1.0                1.0                1.0   \n",
       "2911                1.0                1.0                1.0   \n",
       "2912                1.0                1.0                1.0   \n",
       "2913                1.0                1.0                1.0   \n",
       "2914                1.0                1.0                1.0   \n",
       "2915                1.0                1.0                1.0   \n",
       "2916                1.0                1.0                1.0   \n",
       "2902                1.0                1.0                1.0   \n",
       "2917                1.0                1.0                1.0   \n",
       "2919                1.0                1.0                1.0   \n",
       "2920                1.0                1.0                1.0   \n",
       "2921                1.0                1.0                1.0   \n",
       "2922                1.0                1.0                1.0   \n",
       "2923                1.0                1.0                1.0   \n",
       "2924                1.0                1.0                1.0   \n",
       "2925                1.0                1.0                1.0   \n",
       "2926                1.0                1.0                1.0   \n",
       "2927                1.0                1.0                1.0   \n",
       "2928                1.0                1.0                1.0   \n",
       "2929                1.0                1.0                1.0   \n",
       "2930                1.0                1.0                1.0   \n",
       "2931                1.0                1.0                1.0   \n",
       "2932                1.0                1.0                1.0   \n",
       "2918                1.0                1.0                1.0   \n",
       "2933                1.0                1.0                1.0   \n",
       "2901                1.0                1.0                1.0   \n",
       "2899                1.0                1.0                1.0   \n",
       "2869                1.0                1.0                1.0   \n",
       "2870                1.0                1.0                1.0   \n",
       "2871                1.0                1.0                1.0   \n",
       "2872                1.0                1.0                1.0   \n",
       "2873                1.0                1.0                1.0   \n",
       "2874                1.0                1.0                1.0   \n",
       "2875                1.0                1.0                1.0   \n",
       "2876                1.0                1.0                1.0   \n",
       "2877                1.0                1.0                1.0   \n",
       "2878                1.0                1.0                1.0   \n",
       "2879                1.0                1.0                1.0   \n",
       "2880                1.0                1.0                1.0   \n",
       "2881                1.0                1.0                1.0   \n",
       "2882                1.0                1.0                1.0   \n",
       "2900                1.0                1.0                1.0   \n",
       "2883                1.0                1.0                1.0   \n",
       "2885                1.0                1.0                1.0   \n",
       "2886                1.0                1.0                1.0   \n",
       "2887                1.0                1.0                1.0   \n",
       "2888                1.0                1.0                1.0   \n",
       "2889                1.0                1.0                1.0   \n",
       "2890                1.0                1.0                1.0   \n",
       "2891                1.0                1.0                1.0   \n",
       "2892                1.0                1.0                1.0   \n",
       "2893                1.0                1.0                1.0   \n",
       "2894                1.0                1.0                1.0   \n",
       "2895                1.0                1.0                1.0   \n",
       "2896                1.0                1.0                1.0   \n",
       "2897                1.0                1.0                1.0   \n",
       "2898                1.0                1.0                1.0   \n",
       "2884                1.0                1.0                1.0   \n",
       "2868                1.0                1.0                1.0   \n",
       "2934                1.0                1.0                1.0   \n",
       "2936                1.0                1.0                1.0   \n",
       "2971                1.0                1.0                1.0   \n",
       "2972                1.0                1.0                1.0   \n",
       "2973                1.0                1.0                1.0   \n",
       "2974                1.0                1.0                1.0   \n",
       "2975                1.0                1.0                1.0   \n",
       "2976                1.0                1.0                1.0   \n",
       "2977                1.0                1.0                1.0   \n",
       "2978                1.0                1.0                1.0   \n",
       "2979                1.0                1.0                1.0   \n",
       "2980                1.0                1.0                1.0   \n",
       "2981                1.0                1.0                1.0   \n",
       "2982                1.0                1.0                1.0   \n",
       "2983                1.0                1.0                1.0   \n",
       "2984                1.0                1.0                1.0   \n",
       "2970                1.0                1.0                1.0   \n",
       "2985                1.0                1.0                1.0   \n",
       "2987                1.0                1.0                1.0   \n",
       "2988                1.0                1.0                1.0   \n",
       "2989                1.0                1.0                1.0   \n",
       "2990                1.0                1.0                1.0   \n",
       "2991                1.0                1.0                1.0   \n",
       "2992                1.0                1.0                1.0   \n",
       "2993                1.0                1.0                1.0   \n",
       "2994                1.0                1.0                1.0   \n",
       "2995                1.0                1.0                1.0   \n",
       "2996                1.0                1.0                1.0   \n",
       "2997                1.0                1.0                1.0   \n",
       "2998                1.0                1.0                1.0   \n",
       "2999                1.0                1.0                1.0   \n",
       "3000                1.0                1.0                1.0   \n",
       "2986                1.0                1.0                1.0   \n",
       "\n",
       "      split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0                   1.0                1.0              1.0             0.0   \n",
       "2903                1.0                1.0              1.0             0.0   \n",
       "2904                1.0                1.0              1.0             0.0   \n",
       "2905                1.0                1.0              1.0             0.0   \n",
       "2906                1.0                1.0              1.0             0.0   \n",
       "2907                1.0                1.0              1.0             0.0   \n",
       "2908                1.0                1.0              1.0             0.0   \n",
       "2909                1.0                1.0              1.0             0.0   \n",
       "2910                1.0                1.0              1.0             0.0   \n",
       "2911                1.0                1.0              1.0             0.0   \n",
       "2912                1.0                1.0              1.0             0.0   \n",
       "2913                1.0                1.0              1.0             0.0   \n",
       "2914                1.0                1.0              1.0             0.0   \n",
       "2915                1.0                1.0              1.0             0.0   \n",
       "2916                1.0                1.0              1.0             0.0   \n",
       "2902                1.0                1.0              1.0             0.0   \n",
       "2917                1.0                1.0              1.0             0.0   \n",
       "2919                1.0                1.0              1.0             0.0   \n",
       "2920                1.0                1.0              1.0             0.0   \n",
       "2921                1.0                1.0              1.0             0.0   \n",
       "2922                1.0                1.0              1.0             0.0   \n",
       "2923                1.0                1.0              1.0             0.0   \n",
       "2924                1.0                1.0              1.0             0.0   \n",
       "2925                1.0                1.0              1.0             0.0   \n",
       "2926                1.0                1.0              1.0             0.0   \n",
       "2927                1.0                1.0              1.0             0.0   \n",
       "2928                1.0                1.0              1.0             0.0   \n",
       "2929                1.0                1.0              1.0             0.0   \n",
       "2930                1.0                1.0              1.0             0.0   \n",
       "2931                1.0                1.0              1.0             0.0   \n",
       "2932                1.0                1.0              1.0             0.0   \n",
       "2918                1.0                1.0              1.0             0.0   \n",
       "2933                1.0                1.0              1.0             0.0   \n",
       "2901                1.0                1.0              1.0             0.0   \n",
       "2899                1.0                1.0              1.0             0.0   \n",
       "2869                1.0                1.0              1.0             0.0   \n",
       "2870                1.0                1.0              1.0             0.0   \n",
       "2871                1.0                1.0              1.0             0.0   \n",
       "2872                1.0                1.0              1.0             0.0   \n",
       "2873                1.0                1.0              1.0             0.0   \n",
       "2874                1.0                1.0              1.0             0.0   \n",
       "2875                1.0                1.0              1.0             0.0   \n",
       "2876                1.0                1.0              1.0             0.0   \n",
       "2877                1.0                1.0              1.0             0.0   \n",
       "2878                1.0                1.0              1.0             0.0   \n",
       "2879                1.0                1.0              1.0             0.0   \n",
       "2880                1.0                1.0              1.0             0.0   \n",
       "2881                1.0                1.0              1.0             0.0   \n",
       "2882                1.0                1.0              1.0             0.0   \n",
       "2900                1.0                1.0              1.0             0.0   \n",
       "2883                1.0                1.0              1.0             0.0   \n",
       "2885                1.0                1.0              1.0             0.0   \n",
       "2886                1.0                1.0              1.0             0.0   \n",
       "2887                1.0                1.0              1.0             0.0   \n",
       "2888                1.0                1.0              1.0             0.0   \n",
       "2889                1.0                1.0              1.0             0.0   \n",
       "2890                1.0                1.0              1.0             0.0   \n",
       "2891                1.0                1.0              1.0             0.0   \n",
       "2892                1.0                1.0              1.0             0.0   \n",
       "2893                1.0                1.0              1.0             0.0   \n",
       "2894                1.0                1.0              1.0             0.0   \n",
       "2895                1.0                1.0              1.0             0.0   \n",
       "2896                1.0                1.0              1.0             0.0   \n",
       "2897                1.0                1.0              1.0             0.0   \n",
       "2898                1.0                1.0              1.0             0.0   \n",
       "2884                1.0                1.0              1.0             0.0   \n",
       "2868                1.0                1.0              1.0             0.0   \n",
       "2934                1.0                1.0              1.0             0.0   \n",
       "2936                1.0                1.0              1.0             0.0   \n",
       "2971                1.0                1.0              1.0             0.0   \n",
       "2972                1.0                1.0              1.0             0.0   \n",
       "2973                1.0                1.0              1.0             0.0   \n",
       "2974                1.0                1.0              1.0             0.0   \n",
       "2975                1.0                1.0              1.0             0.0   \n",
       "2976                1.0                1.0              1.0             0.0   \n",
       "2977                1.0                1.0              1.0             0.0   \n",
       "2978                1.0                1.0              1.0             0.0   \n",
       "2979                1.0                1.0              1.0             0.0   \n",
       "2980                1.0                1.0              1.0             0.0   \n",
       "2981                1.0                1.0              1.0             0.0   \n",
       "2982                1.0                1.0              1.0             0.0   \n",
       "2983                1.0                1.0              1.0             0.0   \n",
       "2984                1.0                1.0              1.0             0.0   \n",
       "2970                1.0                1.0              1.0             0.0   \n",
       "2985                1.0                1.0              1.0             0.0   \n",
       "2987                1.0                1.0              1.0             0.0   \n",
       "2988                1.0                1.0              1.0             0.0   \n",
       "2989                1.0                1.0              1.0             0.0   \n",
       "2990                1.0                1.0              1.0             0.0   \n",
       "2991                1.0                1.0              1.0             0.0   \n",
       "2992                1.0                1.0              1.0             0.0   \n",
       "2993                1.0                1.0              1.0             0.0   \n",
       "2994                1.0                1.0              1.0             0.0   \n",
       "2995                1.0                1.0              1.0             0.0   \n",
       "2996                1.0                1.0              1.0             0.0   \n",
       "2997                1.0                1.0              1.0             0.0   \n",
       "2998                1.0                1.0              1.0             0.0   \n",
       "2999                1.0                1.0              1.0             0.0   \n",
       "3000                1.0                1.0              1.0             0.0   \n",
       "2986                1.0                1.0              1.0             0.0   \n",
       "\n",
       "      rank_test_score  \n",
       "0                   1  \n",
       "2903                1  \n",
       "2904                1  \n",
       "2905                1  \n",
       "2906                1  \n",
       "2907                1  \n",
       "2908                1  \n",
       "2909                1  \n",
       "2910                1  \n",
       "2911                1  \n",
       "2912                1  \n",
       "2913                1  \n",
       "2914                1  \n",
       "2915                1  \n",
       "2916                1  \n",
       "2902                1  \n",
       "2917                1  \n",
       "2919                1  \n",
       "2920                1  \n",
       "2921                1  \n",
       "2922                1  \n",
       "2923                1  \n",
       "2924                1  \n",
       "2925                1  \n",
       "2926                1  \n",
       "2927                1  \n",
       "2928                1  \n",
       "2929                1  \n",
       "2930                1  \n",
       "2931                1  \n",
       "2932                1  \n",
       "2918                1  \n",
       "2933                1  \n",
       "2901                1  \n",
       "2899                1  \n",
       "2869                1  \n",
       "2870                1  \n",
       "2871                1  \n",
       "2872                1  \n",
       "2873                1  \n",
       "2874                1  \n",
       "2875                1  \n",
       "2876                1  \n",
       "2877                1  \n",
       "2878                1  \n",
       "2879                1  \n",
       "2880                1  \n",
       "2881                1  \n",
       "2882                1  \n",
       "2900                1  \n",
       "2883                1  \n",
       "2885                1  \n",
       "2886                1  \n",
       "2887                1  \n",
       "2888                1  \n",
       "2889                1  \n",
       "2890                1  \n",
       "2891                1  \n",
       "2892                1  \n",
       "2893                1  \n",
       "2894                1  \n",
       "2895                1  \n",
       "2896                1  \n",
       "2897                1  \n",
       "2898                1  \n",
       "2884                1  \n",
       "2868                1  \n",
       "2934                1  \n",
       "2936                1  \n",
       "2971                1  \n",
       "2972                1  \n",
       "2973                1  \n",
       "2974                1  \n",
       "2975                1  \n",
       "2976                1  \n",
       "2977                1  \n",
       "2978                1  \n",
       "2979                1  \n",
       "2980                1  \n",
       "2981                1  \n",
       "2982                1  \n",
       "2983                1  \n",
       "2984                1  \n",
       "2970                1  \n",
       "2985                1  \n",
       "2987                1  \n",
       "2988                1  \n",
       "2989                1  \n",
       "2990                1  \n",
       "2991                1  \n",
       "2992                1  \n",
       "2993                1  \n",
       "2994                1  \n",
       "2995                1  \n",
       "2996                1  \n",
       "2997                1  \n",
       "2998                1  \n",
       "2999                1  \n",
       "3000                1  \n",
       "2986                1  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ad27dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparam tuning with one data:\n",
    "df = train_set[1].copy()\n",
    "x_train = df\n",
    "y_train = x_train.pop('progress')\n",
    "cat_features = ['PTGENDER', 'PTETHCAT', 'PTMARRY', 'PTRACCAT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c615d7c8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2016 candidates, totalling 10080 fits\n",
      "[CV 1/5; 1/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003\n",
      "[CV 1/5; 1/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003;, score=0.005 total time=   0.1s\n",
      "[CV 2/5; 1/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003\n",
      "[CV 2/5; 1/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003;, score=0.429 total time=   0.2s\n",
      "[CV 3/5; 1/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003\n",
      "[CV 3/5; 1/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003;, score=0.396 total time=   0.2s\n",
      "[CV 4/5; 1/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003\n",
      "[CV 4/5; 1/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003;, score=0.565 total time=   0.2s\n",
      "[CV 5/5; 1/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003\n",
      "[CV 5/5; 1/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.003;, score=0.544 total time=   0.2s\n",
      "[CV 1/5; 2/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006\n",
      "[CV 1/5; 2/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006;, score=0.005 total time=   0.3s\n",
      "[CV 2/5; 2/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006\n",
      "[CV 2/5; 2/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006;, score=0.422 total time=   0.3s\n",
      "[CV 3/5; 2/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006\n",
      "[CV 3/5; 2/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006;, score=0.429 total time=   0.2s\n",
      "[CV 4/5; 2/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006\n",
      "[CV 4/5; 2/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006;, score=0.591 total time=   0.3s\n",
      "[CV 5/5; 2/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006\n",
      "[CV 5/5; 2/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.006;, score=0.456 total time=   0.3s\n",
      "[CV 1/5; 3/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009\n",
      "[CV 1/5; 3/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009;, score=0.014 total time=   0.3s\n",
      "[CV 2/5; 3/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009\n",
      "[CV 2/5; 3/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009;, score=0.453 total time=   0.3s\n",
      "[CV 3/5; 3/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009\n",
      "[CV 3/5; 3/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009;, score=0.396 total time=   0.2s\n",
      "[CV 4/5; 3/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009\n",
      "[CV 4/5; 3/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009;, score=0.614 total time=   0.3s\n",
      "[CV 5/5; 3/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009\n",
      "[CV 5/5; 3/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.009;, score=0.464 total time=   0.2s\n",
      "[CV 1/5; 4/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03\n",
      "[CV 1/5; 4/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03;, score=0.164 total time=   0.2s\n",
      "[CV 2/5; 4/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03\n",
      "[CV 2/5; 4/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03;, score=0.421 total time=   0.2s\n",
      "[CV 3/5; 4/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03\n",
      "[CV 3/5; 4/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03;, score=0.511 total time=   0.3s\n",
      "[CV 4/5; 4/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03\n",
      "[CV 4/5; 4/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03;, score=0.604 total time=   0.3s\n",
      "[CV 5/5; 4/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03\n",
      "[CV 5/5; 4/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.03;, score=0.481 total time=   0.2s\n",
      "[CV 1/5; 5/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06\n",
      "[CV 1/5; 5/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06;, score=0.122 total time=   0.2s\n",
      "[CV 2/5; 5/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06\n",
      "[CV 2/5; 5/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06;, score=0.455 total time=   0.2s\n",
      "[CV 3/5; 5/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06\n",
      "[CV 3/5; 5/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06;, score=0.482 total time=   0.2s\n",
      "[CV 4/5; 5/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06\n",
      "[CV 4/5; 5/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06;, score=0.626 total time=   0.2s\n",
      "[CV 5/5; 5/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06\n",
      "[CV 5/5; 5/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.06;, score=0.490 total time=   0.2s\n",
      "[CV 1/5; 6/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09\n",
      "[CV 1/5; 6/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09;, score=0.289 total time=   0.3s\n",
      "[CV 2/5; 6/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09\n",
      "[CV 2/5; 6/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09;, score=0.446 total time=   0.4s\n",
      "[CV 3/5; 6/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09\n",
      "[CV 3/5; 6/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09;, score=0.614 total time=   0.2s\n",
      "[CV 4/5; 6/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09\n",
      "[CV 4/5; 6/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09;, score=0.537 total time=   0.3s\n",
      "[CV 5/5; 6/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09\n",
      "[CV 5/5; 6/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.09;, score=0.415 total time=   0.3s\n",
      "[CV 1/5; 7/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3\n",
      "[CV 1/5; 7/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3;, score=0.134 total time=   0.3s\n",
      "[CV 2/5; 7/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3\n",
      "[CV 2/5; 7/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3;, score=0.488 total time=   0.3s\n",
      "[CV 3/5; 7/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3\n",
      "[CV 3/5; 7/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3;, score=0.501 total time=   0.3s\n",
      "[CV 4/5; 7/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3\n",
      "[CV 4/5; 7/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3;, score=0.470 total time=   0.3s\n",
      "[CV 5/5; 7/2016] START depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3\n",
      "[CV 5/5; 7/2016] END depth=3, iterations=100, l2_leaf_reg=0, learning_rate=0.3;, score=0.522 total time=   0.3s\n",
      "[CV 1/5; 8/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003\n",
      "[CV 1/5; 8/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003;, score=-0.004 total time=   0.2s\n",
      "[CV 2/5; 8/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003\n",
      "[CV 2/5; 8/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003;, score=0.460 total time=   0.3s\n",
      "[CV 3/5; 8/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003\n",
      "[CV 3/5; 8/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003;, score=0.429 total time=   0.2s\n",
      "[CV 4/5; 8/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003\n",
      "[CV 4/5; 8/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003;, score=0.511 total time=   0.2s\n",
      "[CV 5/5; 8/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003\n",
      "[CV 5/5; 8/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.003;, score=0.481 total time=   0.2s\n",
      "[CV 1/5; 9/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006\n",
      "[CV 1/5; 9/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006;, score=-0.004 total time=   0.2s\n",
      "[CV 2/5; 9/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006\n",
      "[CV 2/5; 9/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006;, score=0.489 total time=   0.2s\n",
      "[CV 3/5; 9/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006\n",
      "[CV 3/5; 9/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006;, score=0.429 total time=   0.2s\n",
      "[CV 4/5; 9/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006;, score=0.565 total time=   0.3s\n",
      "[CV 5/5; 9/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006\n",
      "[CV 5/5; 9/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.006;, score=0.481 total time=   0.2s\n",
      "[CV 1/5; 10/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009\n",
      "[CV 1/5; 10/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009;, score=0.005 total time=   0.2s\n",
      "[CV 2/5; 10/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009\n",
      "[CV 2/5; 10/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009;, score=0.460 total time=   0.2s\n",
      "[CV 3/5; 10/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009\n",
      "[CV 3/5; 10/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009;, score=0.396 total time=   0.2s\n",
      "[CV 4/5; 10/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009\n",
      "[CV 4/5; 10/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009;, score=0.589 total time=   0.2s\n",
      "[CV 5/5; 10/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009\n",
      "[CV 5/5; 10/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.009;, score=0.489 total time=   0.2s\n",
      "[CV 1/5; 11/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03\n",
      "[CV 1/5; 11/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03;, score=0.085 total time=   0.2s\n",
      "[CV 2/5; 11/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03\n",
      "[CV 2/5; 11/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03;, score=0.483 total time=   0.2s\n",
      "[CV 3/5; 11/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03\n",
      "[CV 3/5; 11/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03;, score=0.460 total time=   0.3s\n",
      "[CV 4/5; 11/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03\n",
      "[CV 4/5; 11/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03;, score=0.561 total time=   0.3s\n",
      "[CV 5/5; 11/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03\n",
      "[CV 5/5; 11/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.03;, score=0.497 total time=   0.2s\n",
      "[CV 1/5; 12/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06\n",
      "[CV 1/5; 12/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06;, score=0.193 total time=   0.2s\n",
      "[CV 2/5; 12/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06\n",
      "[CV 2/5; 12/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06;, score=0.408 total time=   0.3s\n",
      "[CV 3/5; 12/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06\n",
      "[CV 3/5; 12/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06;, score=0.510 total time=   0.3s\n",
      "[CV 4/5; 12/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06\n",
      "[CV 4/5; 12/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06;, score=0.512 total time=   0.2s\n",
      "[CV 5/5; 12/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06\n",
      "[CV 5/5; 12/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.06;, score=0.456 total time=   0.3s\n",
      "[CV 1/5; 13/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09\n",
      "[CV 1/5; 13/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09;, score=0.240 total time=   0.3s\n",
      "[CV 2/5; 13/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09\n",
      "[CV 2/5; 13/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09;, score=0.409 total time=   0.2s\n",
      "[CV 3/5; 13/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09\n",
      "[CV 3/5; 13/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09;, score=0.589 total time=   0.2s\n",
      "[CV 4/5; 13/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09\n",
      "[CV 4/5; 13/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09;, score=0.545 total time=   0.2s\n",
      "[CV 5/5; 13/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09\n",
      "[CV 5/5; 13/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.09;, score=0.456 total time=   0.2s\n",
      "[CV 1/5; 14/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3\n",
      "[CV 1/5; 14/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3;, score=0.258 total time=   0.2s\n",
      "[CV 2/5; 14/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3\n",
      "[CV 2/5; 14/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3;, score=0.483 total time=   0.2s\n",
      "[CV 3/5; 14/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3\n",
      "[CV 3/5; 14/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3;, score=0.568 total time=   0.2s\n",
      "[CV 4/5; 14/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3\n",
      "[CV 4/5; 14/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3;, score=0.497 total time=   0.2s\n",
      "[CV 5/5; 14/2016] START depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3\n",
      "[CV 5/5; 14/2016] END depth=3, iterations=100, l2_leaf_reg=1, learning_rate=0.3;, score=0.448 total time=   0.2s\n",
      "[CV 1/5; 15/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003\n",
      "[CV 1/5; 15/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003;, score=-0.004 total time=   0.2s\n",
      "[CV 2/5; 15/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003\n",
      "[CV 2/5; 15/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003;, score=0.460 total time=   0.2s\n",
      "[CV 3/5; 15/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003\n",
      "[CV 3/5; 15/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003;, score=0.429 total time=   0.2s\n",
      "[CV 4/5; 15/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003\n",
      "[CV 4/5; 15/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003;, score=0.483 total time=   0.2s\n",
      "[CV 5/5; 15/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003\n",
      "[CV 5/5; 15/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.003;, score=0.465 total time=   0.2s\n",
      "[CV 1/5; 16/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006\n",
      "[CV 1/5; 16/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006;, score=-0.004 total time=   0.2s\n",
      "[CV 2/5; 16/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006\n",
      "[CV 2/5; 16/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006;, score=0.460 total time=   0.2s\n",
      "[CV 3/5; 16/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006\n",
      "[CV 3/5; 16/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006;, score=0.429 total time=   0.2s\n",
      "[CV 4/5; 16/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006\n",
      "[CV 4/5; 16/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006;, score=0.591 total time=   0.2s\n",
      "[CV 5/5; 16/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006\n",
      "[CV 5/5; 16/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.006;, score=0.514 total time=   0.2s\n",
      "[CV 1/5; 17/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009\n",
      "[CV 1/5; 17/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009;, score=0.014 total time=   0.4s\n",
      "[CV 2/5; 17/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009\n",
      "[CV 2/5; 17/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009;, score=0.429 total time=   0.2s\n",
      "[CV 3/5; 17/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009\n",
      "[CV 3/5; 17/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009;, score=0.396 total time=   0.2s\n",
      "[CV 4/5; 17/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009\n",
      "[CV 4/5; 17/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009;, score=0.564 total time=   0.2s\n",
      "[CV 5/5; 17/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009\n",
      "[CV 5/5; 17/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.009;, score=0.456 total time=   0.2s\n",
      "[CV 1/5; 18/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 18/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03;, score=0.125 total time=   0.3s\n",
      "[CV 2/5; 18/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03\n",
      "[CV 2/5; 18/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03;, score=0.453 total time=   0.3s\n",
      "[CV 3/5; 18/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03\n",
      "[CV 3/5; 18/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03;, score=0.489 total time=   0.3s\n",
      "[CV 4/5; 18/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03\n",
      "[CV 4/5; 18/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03;, score=0.544 total time=   0.2s\n",
      "[CV 5/5; 18/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03\n",
      "[CV 5/5; 18/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.03;, score=0.505 total time=   0.2s\n",
      "[CV 1/5; 19/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06\n",
      "[CV 1/5; 19/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06;, score=0.303 total time=   0.2s\n",
      "[CV 2/5; 19/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06\n",
      "[CV 2/5; 19/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06;, score=0.425 total time=   0.2s\n",
      "[CV 3/5; 19/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06\n",
      "[CV 3/5; 19/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06;, score=0.591 total time=   0.2s\n",
      "[CV 4/5; 19/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06\n",
      "[CV 4/5; 19/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06;, score=0.635 total time=   0.2s\n",
      "[CV 5/5; 19/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06\n",
      "[CV 5/5; 19/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.06;, score=0.505 total time=   0.2s\n",
      "[CV 1/5; 20/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09\n",
      "[CV 1/5; 20/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09;, score=0.348 total time=   0.3s\n",
      "[CV 2/5; 20/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09\n",
      "[CV 2/5; 20/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09;, score=0.350 total time=   0.4s\n",
      "[CV 3/5; 20/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09\n",
      "[CV 3/5; 20/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09;, score=0.690 total time=   0.2s\n",
      "[CV 4/5; 20/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09\n",
      "[CV 4/5; 20/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09;, score=0.523 total time=   0.2s\n",
      "[CV 5/5; 20/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09\n",
      "[CV 5/5; 20/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.09;, score=0.473 total time=   0.3s\n",
      "[CV 1/5; 21/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3\n",
      "[CV 1/5; 21/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3;, score=0.390 total time=   0.3s\n",
      "[CV 2/5; 21/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3\n",
      "[CV 2/5; 21/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3;, score=0.433 total time=   0.2s\n",
      "[CV 3/5; 21/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3\n",
      "[CV 3/5; 21/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3;, score=0.754 total time=   0.3s\n",
      "[CV 4/5; 21/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3\n",
      "[CV 4/5; 21/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3;, score=0.537 total time=   0.3s\n",
      "[CV 5/5; 21/2016] START depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3\n",
      "[CV 5/5; 21/2016] END depth=3, iterations=100, l2_leaf_reg=2, learning_rate=0.3;, score=0.481 total time=   0.3s\n",
      "[CV 1/5; 22/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003\n",
      "[CV 1/5; 22/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003;, score=-0.004 total time=   0.2s\n",
      "[CV 2/5; 22/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003\n",
      "[CV 2/5; 22/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003;, score=0.460 total time=   0.2s\n",
      "[CV 3/5; 22/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003\n",
      "[CV 3/5; 22/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003;, score=0.396 total time=   0.2s\n",
      "[CV 4/5; 22/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003\n",
      "[CV 4/5; 22/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003;, score=0.453 total time=   0.2s\n",
      "[CV 5/5; 22/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003\n",
      "[CV 5/5; 22/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.003;, score=0.497 total time=   0.2s\n",
      "[CV 1/5; 23/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006\n",
      "[CV 1/5; 23/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006;, score=-0.004 total time=   0.2s\n",
      "[CV 2/5; 23/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006\n",
      "[CV 2/5; 23/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006;, score=0.429 total time=   0.2s\n",
      "[CV 3/5; 23/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006\n",
      "[CV 3/5; 23/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006;, score=0.396 total time=   0.2s\n",
      "[CV 4/5; 23/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006\n",
      "[CV 4/5; 23/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006;, score=0.539 total time=   0.3s\n",
      "[CV 5/5; 23/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006\n",
      "[CV 5/5; 23/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.006;, score=0.472 total time=   0.2s\n",
      "[CV 1/5; 24/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009\n",
      "[CV 1/5; 24/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009;, score=0.005 total time=   0.3s\n",
      "[CV 2/5; 24/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009\n",
      "[CV 2/5; 24/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009;, score=0.460 total time=   0.2s\n",
      "[CV 3/5; 24/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009\n",
      "[CV 3/5; 24/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009;, score=0.460 total time=   0.2s\n",
      "[CV 4/5; 24/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009\n",
      "[CV 4/5; 24/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009;, score=0.542 total time=   0.2s\n",
      "[CV 5/5; 24/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009\n",
      "[CV 5/5; 24/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.009;, score=0.448 total time=   0.4s\n",
      "[CV 1/5; 25/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03\n",
      "[CV 1/5; 25/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03;, score=0.111 total time=   0.2s\n",
      "[CV 2/5; 25/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03\n",
      "[CV 2/5; 25/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03;, score=0.422 total time=   0.2s\n",
      "[CV 3/5; 25/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03\n",
      "[CV 3/5; 25/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03;, score=0.489 total time=   0.2s\n",
      "[CV 4/5; 25/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03\n",
      "[CV 4/5; 25/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03;, score=0.553 total time=   0.3s\n",
      "[CV 5/5; 25/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03\n",
      "[CV 5/5; 25/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.03;, score=0.497 total time=   0.2s\n",
      "[CV 1/5; 26/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06\n",
      "[CV 1/5; 26/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06;, score=0.254 total time=   0.2s\n",
      "[CV 2/5; 26/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06\n",
      "[CV 2/5; 26/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06;, score=0.425 total time=   0.2s\n",
      "[CV 3/5; 26/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 26/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06;, score=0.517 total time=   0.3s\n",
      "[CV 4/5; 26/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06\n",
      "[CV 4/5; 26/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06;, score=0.548 total time=   0.2s\n",
      "[CV 5/5; 26/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06\n",
      "[CV 5/5; 26/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.06;, score=0.481 total time=   0.3s\n",
      "[CV 1/5; 27/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09\n",
      "[CV 1/5; 27/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09;, score=0.333 total time=   0.3s\n",
      "[CV 2/5; 27/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09\n",
      "[CV 2/5; 27/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09;, score=0.377 total time=   0.2s\n",
      "[CV 3/5; 27/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09\n",
      "[CV 3/5; 27/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09;, score=0.565 total time=   0.2s\n",
      "[CV 4/5; 27/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09\n",
      "[CV 4/5; 27/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09;, score=0.597 total time=   0.3s\n",
      "[CV 5/5; 27/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09\n",
      "[CV 5/5; 27/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.09;, score=0.456 total time=   0.2s\n",
      "[CV 1/5; 28/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3\n",
      "[CV 1/5; 28/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3;, score=0.333 total time=   0.2s\n",
      "[CV 2/5; 28/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3\n",
      "[CV 2/5; 28/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3;, score=0.446 total time=   0.2s\n",
      "[CV 3/5; 28/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3\n",
      "[CV 3/5; 28/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3;, score=0.710 total time=   0.2s\n",
      "[CV 4/5; 28/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3\n",
      "[CV 4/5; 28/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3;, score=0.548 total time=   0.3s\n",
      "[CV 5/5; 28/2016] START depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3\n",
      "[CV 5/5; 28/2016] END depth=3, iterations=100, l2_leaf_reg=3, learning_rate=0.3;, score=0.481 total time=   0.2s\n",
      "[CV 1/5; 29/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003\n",
      "[CV 1/5; 29/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003;, score=-0.004 total time=   0.2s\n",
      "[CV 2/5; 29/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003\n",
      "[CV 2/5; 29/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003;, score=0.460 total time=   0.2s\n",
      "[CV 3/5; 29/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003\n",
      "[CV 3/5; 29/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003;, score=0.429 total time=   0.3s\n",
      "[CV 4/5; 29/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003\n",
      "[CV 4/5; 29/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003;, score=0.422 total time=   0.2s\n",
      "[CV 5/5; 29/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003\n",
      "[CV 5/5; 29/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.003;, score=0.448 total time=   0.2s\n",
      "[CV 1/5; 30/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006\n",
      "[CV 1/5; 30/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006;, score=-0.004 total time=   0.2s\n",
      "[CV 2/5; 30/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006\n",
      "[CV 2/5; 30/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006;, score=0.429 total time=   0.2s\n",
      "[CV 3/5; 30/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006\n",
      "[CV 3/5; 30/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006;, score=0.429 total time=   0.3s\n",
      "[CV 4/5; 30/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006\n",
      "[CV 4/5; 30/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006;, score=0.565 total time=   0.2s\n",
      "[CV 5/5; 30/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006\n",
      "[CV 5/5; 30/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.006;, score=0.472 total time=   0.2s\n",
      "[CV 1/5; 31/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009\n",
      "[CV 1/5; 31/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009;, score=0.014 total time=   0.2s\n",
      "[CV 2/5; 31/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009\n",
      "[CV 2/5; 31/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009;, score=0.429 total time=   0.3s\n",
      "[CV 3/5; 31/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009\n",
      "[CV 3/5; 31/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009;, score=0.396 total time=   0.3s\n",
      "[CV 4/5; 31/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009\n",
      "[CV 4/5; 31/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009;, score=0.565 total time=   0.2s\n",
      "[CV 5/5; 31/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009\n",
      "[CV 5/5; 31/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.009;, score=0.456 total time=   0.2s\n",
      "[CV 1/5; 32/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03\n",
      "[CV 1/5; 32/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03;, score=0.125 total time=   0.2s\n",
      "[CV 2/5; 32/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03\n",
      "[CV 2/5; 32/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03;, score=0.511 total time=   0.3s\n",
      "[CV 3/5; 32/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03\n",
      "[CV 3/5; 32/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03;, score=0.489 total time=   0.2s\n",
      "[CV 4/5; 32/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03\n",
      "[CV 4/5; 32/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03;, score=0.569 total time=   0.2s\n",
      "[CV 5/5; 32/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03\n",
      "[CV 5/5; 32/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.03;, score=0.497 total time=   0.3s\n",
      "[CV 1/5; 33/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06\n",
      "[CV 1/5; 33/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06;, score=0.221 total time=   0.3s\n",
      "[CV 2/5; 33/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06\n",
      "[CV 2/5; 33/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06;, score=0.455 total time=   0.2s\n",
      "[CV 3/5; 33/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06\n",
      "[CV 3/5; 33/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06;, score=0.570 total time=   0.2s\n",
      "[CV 4/5; 33/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06\n",
      "[CV 4/5; 33/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06;, score=0.533 total time=   0.2s\n",
      "[CV 5/5; 33/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06\n",
      "[CV 5/5; 33/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.06;, score=0.464 total time=   0.3s\n",
      "[CV 1/5; 34/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09\n",
      "[CV 1/5; 34/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09;, score=0.287 total time=   0.3s\n",
      "[CV 2/5; 34/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09\n",
      "[CV 2/5; 34/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09;, score=0.377 total time=   0.2s\n",
      "[CV 3/5; 34/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09\n",
      "[CV 3/5; 34/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09;, score=0.640 total time=   0.2s\n",
      "[CV 4/5; 34/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09\n",
      "[CV 4/5; 34/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09;, score=0.611 total time=   0.2s\n",
      "[CV 5/5; 34/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5; 34/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.09;, score=0.472 total time=   0.3s\n",
      "[CV 1/5; 35/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3\n",
      "[CV 1/5; 35/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3;, score=0.303 total time=   0.3s\n",
      "[CV 2/5; 35/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3\n",
      "[CV 2/5; 35/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3;, score=0.363 total time=   0.2s\n",
      "[CV 3/5; 35/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3\n",
      "[CV 3/5; 35/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3;, score=0.568 total time=   0.2s\n",
      "[CV 4/5; 35/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3\n",
      "[CV 4/5; 35/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3;, score=0.456 total time=   0.3s\n",
      "[CV 5/5; 35/2016] START depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3\n",
      "[CV 5/5; 35/2016] END depth=3, iterations=100, l2_leaf_reg=4, learning_rate=0.3;, score=0.450 total time=   0.2s\n",
      "[CV 1/5; 36/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003\n",
      "[CV 1/5; 36/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003;, score=-0.004 total time=   0.2s\n",
      "[CV 2/5; 36/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003\n",
      "[CV 2/5; 36/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003;, score=0.429 total time=   0.2s\n",
      "[CV 3/5; 36/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003\n",
      "[CV 3/5; 36/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003;, score=0.429 total time=   0.2s\n",
      "[CV 4/5; 36/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003\n",
      "[CV 4/5; 36/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003;, score=0.453 total time=   0.2s\n",
      "[CV 5/5; 36/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003\n",
      "[CV 5/5; 36/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.003;, score=0.489 total time=   0.2s\n",
      "[CV 1/5; 37/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006\n",
      "[CV 1/5; 37/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006;, score=-0.004 total time=   0.3s\n",
      "[CV 2/5; 37/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006\n",
      "[CV 2/5; 37/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006;, score=0.460 total time=   0.2s\n",
      "[CV 3/5; 37/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006\n",
      "[CV 3/5; 37/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006;, score=0.429 total time=   0.3s\n",
      "[CV 4/5; 37/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006\n",
      "[CV 4/5; 37/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006;, score=0.511 total time=   0.2s\n",
      "[CV 5/5; 37/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006\n",
      "[CV 5/5; 37/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.006;, score=0.456 total time=   0.2s\n",
      "[CV 1/5; 38/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009\n",
      "[CV 1/5; 38/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009;, score=0.005 total time=   0.3s\n",
      "[CV 2/5; 38/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009\n",
      "[CV 2/5; 38/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009;, score=0.460 total time=   0.3s\n",
      "[CV 3/5; 38/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009\n",
      "[CV 3/5; 38/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009;, score=0.396 total time=   0.3s\n",
      "[CV 4/5; 38/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009\n",
      "[CV 4/5; 38/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009;, score=0.539 total time=   0.2s\n",
      "[CV 5/5; 38/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009\n",
      "[CV 5/5; 38/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.009;, score=0.448 total time=   0.2s\n",
      "[CV 1/5; 39/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03\n",
      "[CV 1/5; 39/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03;, score=0.125 total time=   0.2s\n",
      "[CV 2/5; 39/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03\n",
      "[CV 2/5; 39/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03;, score=0.483 total time=   0.2s\n",
      "[CV 3/5; 39/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03\n",
      "[CV 3/5; 39/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03;, score=0.489 total time=   0.2s\n",
      "[CV 4/5; 39/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03\n",
      "[CV 4/5; 39/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03;, score=0.523 total time=   0.2s\n",
      "[CV 5/5; 39/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03\n",
      "[CV 5/5; 39/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.03;, score=0.481 total time=   0.3s\n",
      "[CV 1/5; 40/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06\n",
      "[CV 1/5; 40/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06;, score=0.254 total time=   0.3s\n",
      "[CV 2/5; 40/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06\n",
      "[CV 2/5; 40/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06;, score=0.455 total time=   0.2s\n",
      "[CV 3/5; 40/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06\n",
      "[CV 3/5; 40/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06;, score=0.570 total time=   0.3s\n",
      "[CV 4/5; 40/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06\n",
      "[CV 4/5; 40/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06;, score=0.572 total time=   0.2s\n",
      "[CV 5/5; 40/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06\n",
      "[CV 5/5; 40/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.06;, score=0.472 total time=   0.2s\n",
      "[CV 1/5; 41/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.09\n",
      "[CV 1/5; 41/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.09;, score=0.303 total time=   0.2s\n",
      "[CV 2/5; 41/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.09\n",
      "[CV 2/5; 41/2016] END depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.09;, score=0.356 total time=   0.3s\n",
      "[CV 3/5; 41/2016] START depth=3, iterations=100, l2_leaf_reg=5, learning_rate=0.09\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[223], line 10\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatboost_train\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mct\u001b[39;00m\n\u001b[1;32m      3\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepth\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m11\u001b[39m)),                       \u001b[38;5;66;03m# 6-10 is recommend\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;241m0.003\u001b[39m,\u001b[38;5;241m0.006\u001b[39m, \u001b[38;5;241m0.009\u001b[39m,\u001b[38;5;241m0.03\u001b[39m,\u001b[38;5;241m0.06\u001b[39m,\u001b[38;5;241m0.09\u001b[39m,\u001b[38;5;241m0.3\u001b[39m],   \u001b[38;5;66;03m# default: 0.03\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \n\u001b[1;32m      9\u001b[0m }\n\u001b[0;32m---> 10\u001b[0m \u001b[43mct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcatboost_greedy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcat_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Dropbox/ADNI/D/code/modeling/catboost_train.py:16\u001b[0m, in \u001b[0;36mcatboost_greedy\u001b[0;34m(data, label, params, cat_features, fold, seed)\u001b[0m\n\u001b[1;32m     14\u001b[0m \t\t\t\t\t\t\tscoring = 'matthews_corrcoef' # outcome imbalanced\n\u001b[1;32m     15\u001b[0m \t\t\t\t\t\t\t)\n\u001b[0;32m---> 16\u001b[0m model_greedy.fit(data, label)\n\u001b[1;32m     17\u001b[0m output = pd.DataFrame(model_greedy.cv_results_).sort_values(\"rank_test_score\")\n\u001b[1;32m     18\u001b[0m return output\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/joblib/parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/catboost/core.py:5128\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5126\u001b[0m     CatBoostClassifier\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5128\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5129\u001b[0m \u001b[43m          \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5130\u001b[0m \u001b[43m          \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/catboost/core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2351\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2353\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[1;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2355\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2361\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/catboost/core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1759\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1760\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:4623\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:4672\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "reload(ct)\n",
    "# import catboost_train as ct\n",
    "params = {\n",
    "    'depth':list(range(3,11)),                       # 6-10 is recommend\n",
    "    'learning_rate':[0.003,0.006, 0.009,0.03,0.06,0.09,0.3],   # default: 0.03\n",
    "    'iterations':[100,200,300,500,1000,2000],\n",
    "    'l2_leaf_reg':list(range(0,6)),  # default 3\n",
    "    \n",
    "}\n",
    "ct.catboost_greedy(x_train, y_train, params=params, cat_features=cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "24afa6dd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For multi-metric scoring, the parameter refit must be set to a scorer key or a callable to refit an estimator with the best parameter setting on the whole data and make the best_* attributes available for that metric. If this is not needed, refit should be set to False explicitly. True was passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[218], line 18\u001b[0m\n\u001b[1;32m      9\u001b[0m mod_cat \u001b[38;5;241m=\u001b[39m cat\u001b[38;5;241m.\u001b[39mCatBoostClassifier(cat_features\u001b[38;5;241m=\u001b[39mcat_features, random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, \n\u001b[1;32m     10\u001b[0m                                  early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m     11\u001b[0m                                 )\n\u001b[1;32m     12\u001b[0m cv_cat \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     13\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m mod_cat, \n\u001b[1;32m     14\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     15\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m     16\u001b[0m     scoring \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatthews_corrcoef\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# because outcome imbalanced\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n\u001b[0;32m---> 18\u001b[0m \u001b[43mcv_cat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m       \n\u001b[1;32m     19\u001b[0m display( pd\u001b[38;5;241m.\u001b[39mDataFrame(cv_cat\u001b[38;5;241m.\u001b[39mcv_results_)\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrank_test_score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)  )\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# cat_params = cv_cat.best_params_\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/sklearn/model_selection/_search.py:779\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    778\u001b[0m     scorers \u001b[38;5;241m=\u001b[39m _check_multimetric_scoring(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring)\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_refit_for_multimetric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     refit_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit\n\u001b[1;32m    782\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/boost/lib/python3.8/site-packages/sklearn/model_selection/_search.py:720\u001b[0m, in \u001b[0;36mBaseSearchCV._check_refit_for_multimetric\u001b[0;34m(self, scores)\u001b[0m\n\u001b[1;32m    713\u001b[0m valid_refit_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit \u001b[38;5;129;01min\u001b[39;00m scores\n\u001b[1;32m    715\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid_refit_dict\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit)\n\u001b[1;32m    719\u001b[0m ):\n\u001b[0;32m--> 720\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(multimetric_refit_msg)\n",
      "\u001b[0;31mValueError\u001b[0m: For multi-metric scoring, the parameter refit must be set to a scorer key or a callable to refit an estimator with the best parameter setting on the whole data and make the best_* attributes available for that metric. If this is not needed, refit should be set to False explicitly. True was passed."
     ]
    }
   ],
   "source": [
    "\n",
    "# params:\n",
    "params = {\n",
    "    'depth':list(range(3,11)),                       # 6-10 is recommend\n",
    "    'learning_rate':[0.003,0.006, 0.009,0.03,0.06,0.09,0.3],   # default: 0.03\n",
    "    'iterations':[100,200,300,500,1000,2000],\n",
    "    'l2_leaf_reg':list(range(0,6)),  # default 3\n",
    "    \n",
    "}\n",
    "mod_cat = cat.CatBoostClassifier(cat_features=cat_features, random_seed=0, verbose=1000, \n",
    "                                 early_stopping_rounds=100\n",
    "                                )\n",
    "cv_cat = GridSearchCV(\n",
    "    estimator = mod_cat, \n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    scoring = ['roc_auc','matthews_corrcoef']  # because outcome imbalanced\n",
    ")\n",
    "cv_cat.fit(x_train, y_train)       \n",
    "display( pd.DataFrame(cv_cat.cv_results_).sort_values(\"rank_test_score\").head(10)  )\n",
    "# cat_params = cv_cat.best_params_\n",
    "cat_params = ml.vote_hyperparam(cv_cat.cv_results_, 1) # top 1 as hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4d350b23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 6, 'l2_leaf_reg': 2, 'learning_rate': 0.03, 'iterations': 2000, 'early_stopping_rounds': 100, 'loss_function': 'CrossEntropy'}\n",
      "Dataset 1, Iteration 228 has lowest log loss: 0.2623170653995748\n",
      "Dataset 2, Iteration 369 has lowest log loss: 0.25341289850465615\n",
      "Dataset 3, Iteration 305 has lowest log loss: 0.27104921699878337\n",
      "Dataset 4, Iteration 207 has lowest log loss: 0.2656591623673335\n",
      "Dataset 5, Iteration 222 has lowest log loss: 0.2595931635652817\n"
     ]
    }
   ],
   "source": [
    "from catboost import Pool, cv \n",
    "cat_params = ml.vote_hyperparam(cv_cat.cv_results_, 1)\n",
    "cat_features = ['PTGENDER', 'PTETHCAT', 'PTMARRY', 'PTRACCAT']\n",
    "it = 2000\n",
    "cat_params['iterations'] = it\n",
    "cat_params['early_stopping_rounds'] = it//20\n",
    "cat_params[\"loss_function\"] = \"Logloss\"\n",
    "print(cat_params)\n",
    "# choose one of the 5 imputed dataset for final modeling:\n",
    "for i, df in train_set.items():\n",
    "    x_train = df.copy()\n",
    "    y_train = x_train.pop('progress')\n",
    "    cv_data = Pool(data=x_train, label=y_train, cat_features=cat_features)\n",
    "    cv_result = cv(cv_data, params=cat_params, logging_level=\"Silent\",\n",
    "                   partition_random_seed = 5,\n",
    "                   fold_count=5, stratified=True)  # default is stratified\n",
    "    print(f\"Dataset {i}, Iteration {np.argmin(cv_result['test-CrossEntropy-mean'])} has lowest CrossEntropy: \\\n",
    "{np.min(cv_result['test-CrossEntropy-mean'])}\")   # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "99a37eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(cv_result.iloc[:,1])\n",
    "float('Inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3fe077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "be197cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup: {'depth': 3, 'l2_leaf_reg': 2, 'learning_rate': 0.03, 'iterations': 1000, 'early_stopping_rounds': 100, 'loss_function': 'CrossEntropy'}, 5-fold CV with stratification\n"
     ]
    }
   ],
   "source": [
    "df = train_set[2].copy()  # > use dataset 5 for model training due to lowest loss\n",
    "x_train = df.copy()       # dataset 1 may have bias \n",
    "y_train = x_train.pop('progress')\n",
    "x_test = test_set[1].copy()       # for drawing one learning curve as represent\n",
    "y_test = x_test.pop('progress')\n",
    "cat_features = ['PTGENDER', 'PTETHCAT', 'PTMARRY', 'PTRACCAT']\n",
    "# reset the tree number based on CV results:\n",
    "cat_params[\"loss_function\"] = \"Logloss\"\n",
    "cat_params[\"iterations\"] = 1000\n",
    "cat_params['early_stopping_rounds'] = 100\n",
    "cat_params[\"loss_function\"] = \"CrossEntropy\"\n",
    "## final model training\n",
    "cv_model = ml.catboost_cv(data=x_train, label=y_train, fold=5, \n",
    "               params=cat_params, cat_features=cat_features, seed=777)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5cdf05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_cat = {}   # to save avg train/test predicted outcome & prob \n",
    "result_cat['train_pred'] = mod_cat.predict(x_train)\n",
    "result_cat['train_prob'] = mod_cat.predict_proba(x_train)[:,1]\n",
    "for i, df_test in test_set.items():\n",
    "    x_test = df_test.copy()\n",
    "    y_test = x_test.pop('progress')\n",
    "    if 'test_pred' in result_cat:\n",
    "        result_cat['test_pred'] += mod_cat.predict(x_test)\n",
    "        result_cat['test_prob'] += mod_cat.predict_proba(x_test)[:,1]\n",
    "    else: # 1st iteration\n",
    "        result_cat['test_pred'] = mod_cat.predict(x_test)\n",
    "        result_cat['test_prob'] = mod_cat.predict_proba(x_test)[:,1]\n",
    "result_cat['test_pred'] = np.where(result_cat['test_pred'] >= 3, 1, 0)\n",
    "result_cat['test_prob'] = result_cat['test_prob']/5\n",
    "dc.save_py(result_cat, \"../output/result_cat_imp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e623264f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AV45': 0.35752583029140284,\n",
       " 'EcogSPOrgan': 0.25207563585439996,\n",
       " 'EcogSPDivatt': 0.2417519361063477,\n",
       " 'EcogSPVisspat': 0.38125130858789424,\n",
       " 'EcogSPPlan': 0.261054059717208,\n",
       " 'EcogPtOrgan': 0.27200497541243807,\n",
       " 'EcogSPTotal': 0.3218369936569415,\n",
       " 'EcogSPMem': 0.29325619208888537,\n",
       " 'MOCA': 0.15826405925951367,\n",
       " 'EcogSPLang': 0.40061121893268986,\n",
       " 'EcogPtDivatt': 0.3244667756023878,\n",
       " 'EcogPtVisspat': 0.22146186269123982,\n",
       " 'EcogPtLang': 0.23048943309298683,\n",
       " 'EcogPtMem': 0.25939603495772096,\n",
       " 'EcogPtTotal': 0.31865684163786423,\n",
       " 'EcogPtPlan': 0.31254986386369327,\n",
       " 'TAU_UPENN': 0.2621918533535059,\n",
       " 'PTAU_UPENN': 0.14115619640685098,\n",
       " 'ABETA_UPENN': 0.2106767975681598,\n",
       " 'FDG': 0.17897272160925218,\n",
       " 'Entorhinal': 0.19974357774928286,\n",
       " 'Fusiform': 0.20740452802701803,\n",
       " 'MidTemp': 0.24227210229587196,\n",
       " 'Hippocampus': 0.1855376611849286,\n",
       " 'Ventricles': 0.1765246147609712,\n",
       " 'WholeBrain': 0.2001887155264081,\n",
       " 'IMAGEUID': 0.22298404861414717,\n",
       " 'ICV': 0.20619079365980325,\n",
       " 'TRABSCOR': 0.20498360831216741,\n",
       " 'FAQ': 0.278696017846581,\n",
       " 'CDRSB': 0.14132532756488095,\n",
       " 'ADAS13': 0.20517521611376813,\n",
       " 'RAVLT_perc_forgetting': 0.16479766796715525,\n",
       " 'RAVLT_forgetting': 0.22674332676646314,\n",
       " 'PTETHCAT': 0.18474504254494892,\n",
       " 'APOE4': 0.17854277711481883,\n",
       " 'PTMARRY': 0.3193917525794066,\n",
       " 'LDELTOTAL': 0.06121477846676788,\n",
       " 'RAVLT_immediate': 0.21452352035539254,\n",
       " 'MMSE': 0.13845702286391182,\n",
       " 'RAVLT_learning': 0.1622035716968536,\n",
       " 'ADAS11': 0.2750456114717733,\n",
       " 'PTRACCAT': 0.13767747424789392,\n",
       " 'mPACCtrailsB': 0.30929915294827454,\n",
       " 'mPACCdigit': 0.26378991804391316,\n",
       " 'ADASQ4': 0.23138759264209824,\n",
       " 'PTEDUCAT': 0.23940841895759513,\n",
       " 'PTGENDER': 0.04021799498000225,\n",
       " 'AGE': 0.19073398084382417,\n",
       " 'SITE': 0.19624866486701129,\n",
       " 'progress': 88.5948949282947}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feat = dict(zip(mod_cat.feature_names_, \n",
    "                    mod_cat.get_feature_importance() ))\n",
    "# dc.save_py(cat_feat, \"../output/cat_feat\")\n",
    "# confusion_matrix(y_test, mod_cat.predict(x_test))\n",
    "cat_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3e785128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[248,  85],\n",
       "       [  9,  19]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1369ae1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import shap\n",
    "explainer = shap.TreeExplainer(mod_cat)\n",
    "# explainer = shap.Explainer(mod_cat)\n",
    "for c in cat_features:\n",
    "    x_train[c] = x_train[c].astype('category')\n",
    "shap_values = explainer.shap_values(x_train)\n",
    "#shap.plots.beeswarm(shap_values)\n",
    "shap.summary_plot(shap_values, max_display=10, feature_names=x_train.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
